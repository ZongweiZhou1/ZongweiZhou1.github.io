<!DOCTYPE html>
<html lang="zh-CN">

  
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  <meta name="author" content="董沅鑫, yuanxin.me@gmail.com">
  
  
  
  <title>深度学习-检测器的评价指标 mAP [代码] | YixiaoZhou&#39;s blog</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="deep-learning,object-detection,metric,mAP,">
  

  <script>
    console.log('\n%c Hexo-theme-bmw v4.0 ' + '%c 🎉 https://github.com/dongyuanxin/theme-bmw 🎉\n' + '\n%c View demo online ' + '%c 🔍 https://godbmw.com/ 🔍  \n' , 'color: #fadfa3; background: #030307; padding:3px 0;', '', 'color: #fadfa3; background: #030307; padding:3px 0;', '');
  </script>

  
    <meta name="description" content="海阔全是浪，天高皆是霾。">
  

  

  
    <link rel="icon" href="/images/fvatar2.png">
    <link rel="apple-touch-icon" href="/images/touch-icon.png">
  

  <link href="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/base.css">
<link rel="stylesheet" href="/icon/iconfont.css">
<link rel="stylesheet" href="/css/github-markdown.css">
<link rel="stylesheet" href="/css/highlight.css">

  <script src="/js/util.js"></script>
<script src="/js/valine.min.js"></script>

  

  
    <link href="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.css" rel="stylesheet">
    <script src="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.js" async></script>
  

  
    <link href="https://cdn.bootcss.com/social-share.js/1.0.16/css/share.min.css" rel="stylesheet">
  
  
  <script src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js" async></script>
  
  
    <script src="//cdn.jsdelivr.net/npm/leancloud-storage@3.11.0/dist/av-min.js"></script>
  

</head>

  <body>

    

    <div id="app">

      <div class="header-wrap">
  <header>
    <div class="site-brand">
      <div class="site-title">
        <a href="/">YiXiaoZhou</a>
      </div>
    </div>
    <nav class="site-navigation">
      <ul class="nav-menu">
      
        <li class="nav-item" data-path="/">
          
            <a href="/" target="_self">
              主页
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/archives/">
          
            <a href="/archives/" target="_self">
              归档
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/friends/">
          
            <a href="/friends/" target="_self">
              友链
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/about/">
          
            <a href="/about/" target="_self">
              关于
            </a>
          
        </li>
      
        <li class="nav-item" data-path>
          
            <a href="javascript:void(0);" v-else>抓到我</a>
            <ul class="nav-menu--dropdown">
              
                <li>
                  <a href="https://github.com/ZongweiZhou1" target="_blank">
                    Github
                  </a>
                </li>
              
                <li>
                  <a href="https://www.facebook.com/duncon.chou" target="_blank">
                    Facebook
                  </a>
                </li>
              
                <li>
                  <a href="https://weibo.com/u/3231820650/home?wvr=5" target="_self">
                    weibo
                  </a>
                </li>
              
            </ul>
          
        </li>
      
      </ul>
    </nav>
    <i class="iconfont icon-menu"></i>
  </header>
</div>

<script>
  let links = document.querySelectorAll('.nav-item');
  for(let link of links){
    let childrenLink = link.querySelector('ul');
    link.addEventListener('mouseenter', () => {
      if(childrenLink) {
        childrenLink.className = "nav-menu--dropdown active";
      }
    })
    link.addEventListener('mouseleave', () => {
      if(childrenLink) {
        childrenLink.className = "nav-menu--dropdown";
      }
    })
  }
  let rootRealPath = getRealPath(window.location.pathname, true);
  for(let link of links) {
    let linkPath = link.getAttribute("data-path");
    if(linkPath && getRealPath(linkPath, true) === rootRealPath) {
      link.className = "nav-item hover";
    }
  }

  let iconMenu = document.querySelector("i.iconfont.icon-menu"),
    iconMenuClicked = false;
  let navDOM = document.querySelector("nav.site-navigation");
  iconMenu.addEventListener("click", () => {
    iconMenuClicked 
      ? navDOM.className = "site-navigation active"
      : navDOM.className = "site-navigation";
    iconMenuClicked = !iconMenuClicked;
  })
</script>

      








<div class="container post-index">

  

<div class="post">
  <h1 class="article-title">
    <span>深度学习-检测器的评价指标 mAP [代码]</span>
  </h1>
  <div class="article-top-meta">
    <span>
      发布 : 
      2019-05-28
    </span>
    
    
      <span>
        浏览 : <span class="article-timer" data-identity="mAP"></span>
      </span>
    
  </div>

  

  <div class="article-content">
    <div class="markdown-body">
      <blockquote>
<p>本文翻译自<a href="https://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/" target="_blank" rel="noopener">Measuring Object Detection models - mAP - What is Mean Average Precision?</a></p>
</blockquote>
<p>对于大多数利用机器学习方法求解的问题来说一般都会存在多个可用模型。 每一个模型都有自己的特点，从而在不同的因素作用下，其表现性能也会出现差异。</p>
<p>模型的性能一般通过其在某个数据集上的表现来评价， 一般这个数据集是对应于训练集的“验证集”或者“测试集”。 性能的定量评价可以有多重指标，比如 acc， pre和recall等。具体选择哪一种指标取决于具体应用和场景。而对于同一种应用，找到一个能够公正合理的比较不同模型的指标则非常重要。</p>
<p>这篇文章我们将会讲一讲目标检测问题中最常见的评价指标 mAP, (The Mean Average Precision)</p>
<p>大多数任务中，评价指标都是通俗易懂且容易计算的，比如二分类任务中的正确度(precision)和召回率(recall)都是直观且容易计算的。</p>
<p>但目标检测问题却是个相当与众不同而且比较有意思的任务。</p>
<p><em>在目标检测任务中，假设检测器从一幅含猫的图像中检测到了猫，但如果没有定位到猫的位置，那结果没有任何意义。</em></p>
<p>所以在目标检测任务中需要预测图像中目标是否出现(occurence)的同时确定目标位置， 那么该如何度量这种指标呢？</p>
<p>首先，我们需要先定义一下什么事目标检测问题。</p>
<h3 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h3><p>目标检测是指：</p>
<p><strong>“ 给定一幅图像，从图像中找到目标，确定目标的位置并分类目标”</strong></p>
<p>由于目标检测模型一般指定了学习的类别， 因此检测模型只需要定位于区分这些指定的类别。另外一般使用矩形框<strong>bounding box</strong>来定位目标。</p>
<p>所以，目标检测任务包含定位和分类两个子问题。</p>
<p>下面要介绍的mAP指标特别适合那些定位不同类目标的算法，所以<strong>mAP可以用来评估下图中的定位模型，目标检测模型和目标分割模型。</strong></p>
<p>![image processing problems](mAP/image processing problems.png)</p>
<hr>
<h3 id="评价目标检测模型"><a href="#评价目标检测模型" class="headerlink" title="评价目标检测模型"></a>评价目标检测模型</h3><h4 id="为什么选择-mAP指标？"><a href="#为什么选择-mAP指标？" class="headerlink" title="为什么选择 mAP指标？"></a>为什么选择 mAP指标？</h4><p>在目标检测任务中， 每张图像都可能包含不同类别中的不同目标。而这些目标的定位和分类都需要评估。 因此图像分类任务中的标准评价指标不能直接应用到目标检测任务中。 于是mAP进入了视野。</p>
<h4 id="关于ground-truth"><a href="#关于ground-truth" class="headerlink" title="关于ground truth"></a>关于ground truth</h4><p>无论是什么算法，评估算法性能都是比较算法的输出和样本的真是标签。对于目标检测任务，ground truth 数据包括<strong>图像</strong>、<strong>目标的类别</strong>以及目标在图像中真是的<strong>标定框</strong>。</p>
<p>如下图所示， 图像，类别和标定框。当然，一般数据集的ground truth数据都是给定一幅图像以及对应的一串包含类别和标定框信息的文本内容。我们将文本内容表现在图像上从而更直观。</p>
<p>![ground truth data](mAP/ground truth data.png)</p>
<p>下面我们重点来介绍下mAP是如何计算的<strong>get our hands dirty</strong>, 首先我们假设已经获得某个检测器在验证集上的检测结果，希望评价这个检测器的性能。</p>
<h4 id="计算mAP"><a href="#计算mAP" class="headerlink" title="计算mAP"></a>计算mAP</h4><p>检测器一般会输出大量的预测结果，但是其中大部分预测的置信度都比较低，所以在评估时只考虑那些置信度超出指定阈值的预测结果。</p>
<p>将验证集的某张图像输入检测器中，经过与预测结果置信度阈值筛选后的预测结果就是检测器的最终输出。</p>
<p>比如下图：</p>
<p>![detector results](mAP/detector results.png)</p>
<p>我们可以很直观的说这些检测是正确的，那么如何该如何量化的表示检测结果呢？</p>
<p>首先我们需要度量这些检测结果的正确性。一般使用 IOU （Intersection over Union) 来预测boundingbox的正确性。 IoU是一个非常简单的视觉量。</p>
<p>下面详细的介绍了IoU的计算过程。</p>
<h4 id="IOU"><a href="#IOU" class="headerlink" title="IOU"></a>IOU</h4><p>IoU是指预测的bounding box与真实的bounding box的交集面积与并集面积的壁纸。也被称为Iaccard Index, 最早是由Paul Jaccard在19世纪初提出。 </p>
<p>为了计算交并值，需要将预测框和真实框重叠在一起。对于每一类而言，检测框和真实框重叠的部分称为交集，而检测框和真实框覆盖的总区域称为并集。如下图中关于<code>马</code> 这类的交并比</p>
<p>![iou of horse](mAP/iou of horse.png)</p>
<p>IoU计算的图形化表示如下</p>
<p>![iou graph format](mAP/iou graph format.png)</p>
<h4 id="识别正确的检测并计算正确率和召回率"><a href="#识别正确的检测并计算正确率和召回率" class="headerlink" title="识别正确的检测并计算正确率和召回率"></a>识别正确的检测并计算正确率和召回率</h4><p>和所有的机器学习算法一样，为了计算正确率和召回率，首先需要区分True Positives， False Positives, True Negatives 和 False Negatives.</p>
<p>我们使用IoU来筛选True和FALSE Positives。大多数情况下IoU的阈值为$0.5$, 也就是说当一个检测与同类别的某个ground truth 框的IoU大于 0.5时认为这个检测框属于True positive， 否则被认为是False Positive。 COCO数据集评测时建议通过交叉验证来获得IoU的阈值，这里为了简单，我们采取PASCAL VOC的度量标准， 即将阈值固定为0.5</p>
<p>计算召回率时，需要计数negative的个数，按照分类问题中的定义，图像中所有没预测到目标的部分都可以认为是负样本，但这种假设导致true negative没有任何实际意义，（即true negative可能就只是背景）。所以这里只计算“False” Negatives， 即没有被检测到的目标的个数。</p>
<p>另外一个需要考虑的因素是模型给出的每个检测的置信度。 通过置信度阈值的调整，划分为正样本positives的检测肯定不同。基本上所有的预测，（与类别无关），如果置信度大于阈值就是positive box，小于阈值就是negative box。</p>
<p>对于每一张图像，其groundtruth数据能够得知图像中每一类目标的真实个数。</p>
<p>通过阈值筛选出所有的positive detections之后，可以计算positive detections与ground truth之间的IoU。 然后利用这些数值与预先设定的IoU阈值可以找出每一张图像中correct detections的个数。从而计算出每一类的正确率precision<br>$$<br>\frac{TP}{TP+FP}=\frac{TP}{P}<br>$$<br>获得正确检测(True Positives)的个数，以及错误检测(False Positive)的个数后, 其召回率，即所有的ground truth中检测到的比率可以如下计算<br>$$<br>rec = \frac{TP}{FN+TP} = \frac{TP}{|G_t|}<br>$$</p>
<h4 id="计算mAP-1"><a href="#计算mAP-1" class="headerlink" title="计算mAP"></a>计算mAP</h4><ul>
<li><p>使用PASCAL VOC的评价标准。</p>
<p>mAP在不同的领域有着不同的定义。 该度量广泛应用于信息检索和目标检测领域。 而在这两个领域中mAP的计算方式也不同。 这里讲的是目标检测领域内的mAP计算方式。</p>
<p>目标检测领域内mAP是PASCAL VOC Challenge首先形式化表述的。 详见具体论文<a href="https://tarangshah.com/blog/assets/ijcv_voc09.pdf" target="_blank" rel="noopener">paper</a></p>
<p>我们本节计算mAP中使用的pre和rec计算方式和前面一节方法相同。</p>
<p>正如前文所说，计算pre和rec时，有两个很重要的阈值， 即置信度阈值和IoU阈值。</p>
<p>IoU是一种简单的几何度量，可以很容易的标准化处理，比如PASCAL VOC中全部基于IoU=0.5条件下计算mAP， COCO则更进一步在不同的IoU阈值$5% \sim 95%$下计算mAP。但置信度阈值却随着模型不同变化很大。在一个模型中$50%$置信度很可能等价于其他模型中$80%$的置信度， 这就会导致pre-rec曲线形状差别很大。于是PASCAL VOC的组织者提出了一种解决办法。</p>
<p>文章中建议计算一种AP的度量。</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; For a given task and class, the precision/recall curve is computed from a method’s ranked output. Recall is defined as the proportion of all positive examples ranked above a given rank. Precision is the proportion of all examples above that rank which are from the positive class. The AP summarises the shape of the precision/recall curve, and is defined as the mean precision at a set of eleven equally spaced recall levels [0,0.1,...,1]:</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>也就是说将置信度阈值划分为11个不同的取值， 使得每一个阈值确定的recall分别为$0, 0.1, 0.2, …, 0.9, 1.0$ </p>
<p>于是 AP定义为这11个rec对应的pre的平均值。 而mAP则是所有类别的AP的均值。</p>
</li>
</ul>
<p>  <em>个人分析：召回率的计算是TP与所有ground truth的比值，ground truth的个数是一直的，那么就可以通过选择不同个数的TP来保证recall在特定的数值上。因此具体计算时可以将detections按照置信度降序排列，然后已从从前往后选择不同个数的TP获得对应的recall，同时计算对应的pre</em>。</p>
<p>  在计算precision时采用的是一种插值方法：</p>
<blockquote>
<figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; The precision at each recall level r is interpolated by taking the maximum precision measured for a method for which the corresponding recall exceeds r</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>  即对于某个recall值r， precision值取所有recall&gt;r值中的最大值， 保证了p-r曲线单调不增<br>  $$<br>  p_{interp}(r) = max_{\hat{r}\gt r} p(\hat{r})<br>  $$</p>
<p>关于计算recall对应的precision时可能有点难理解，下面我们通过示例来解释一下<a href="https://github.com/rafaelpadilla/Object-Detection-Metrics" target="_blank" rel="noopener">example</a></p>
<p>假设检测器对下面7张图片的检测结果为（绿色标识ground truth， 红色表示检测结果， 数字表示置信度）</p>
<p>![detection example](mAP/detection example.png)</p>
<p>那么如果将IoU阈值设为$0.3$,就可以判断每个检测是否是真正的positive， 在计算IoU进行配对时，每个ground truth最多只能对应一个检测，所以当多个检测与同一个ground truth IoU都大于阈值时，选择最大IoU的那个检测，其余的都不能分配给这个ground truth，再与其他的ground truth匹配。</p>
<p>![pos or neg](mAP/pos or neg.png)</p>
<p>然后对所有的检测按照置信度降序排列，然后通过逐渐增多认为是positive的检测的个数，可以得到每个阈值下对应的rec和pre</p>
<p>![acc pre and acc rec](mAP/acc pre and acc rec.png)</p>
<p>Acc TP， Acc FP 表示将每个检测的置信度设为阈值时的累积TP和FP。 由累积的TP和FP可以计算每个阈值下的pre和rec<br>$$<br>pre=\frac{tp_a}{ tp_a + fp_a}\<br>rec = \frac{tp_a}{N_d}<br>$$<br>那么将每一对(rec, pre)绘制在平面上得到：</p>
<p>![pre-rec curver](mAP/pre-rec curver.png)</p>
<p>可以返现曲线并不是单调的，而且一个rec可能对应着多个pre，这时候采用11点插值的做法是，将rec均匀采样为11个点，每一个点可能并不恰好对应于上图中的节点，比如rec没有等于0.1的点，这时候就需要插值得到对应的点的坐标(rec, pre).  AP是pre-rec曲线的AUC（area Under Curve）</p>
<p>按照上文所说，每一个选中的rec对应的pre是大于该rec的所有点中最大的pre值。于是得到下图. 比如 rec=0.0时肯定找不到对应的点，这时候找所有rec&gt;0.0时的点对应的最大pre值作为0.0对应的pre，同理像是rec=0.2， rec=0.3时找到的对应pre都与rec=0.4时相同。</p>
<p>![pre interplation](mAP/pre interplation.png)</p>
<p>那么阶梯状连接所有的插值点，计算线下面积就是VOC标准下的mAP值。<br>$$<br>AP = \frac{1}{11}(1 +0.6666+0.4285+0.4285+0.4285+0+0+0+0+0) = 26.84%<br>$$<br><strong>而采用COCO标准的计算方法不同</strong></p>
<p>COCO计算所有点对应的rec和pre， 而不是对rec进行均匀采样。其一般操作如下图所示, rec从1逐步下降到0， pre选择遍历过程中出现的最大值。</p>
<p><img src="/2019/05/28/mAP/coco_mAP.png" alt="coco-mAP"></p>
<p>所以COCO标准下，同样的检测结果， mAP计算为<br>$$<br>A1 = (0.0666-0)<em>1=0.0666; \quad  A2 = (0.13333-0.0666) * 0.6666 - 0.0445\<br>A3 = (0.4-0.1333) * 0.4285 = 0.1143; \quad A4 = (0.4666-0.4)</em>0.3043 = 0.0203\<br>AP = 24.46%<br>$$<br>发现两个标准下还是存在不同的，其实对比两张曲线图可以发现线下面积的不同。首先VOC是是rec进行了均匀采样，而COCO没有。其次COCO对原始曲线的包络更紧致，也更准确。</p>
<p><img src="/2019/05/28/mAP/compare.png" alt="compare"></p>
<p>一些比较mAP值时需要注意的地方</p>
<ul>
<li>mAP是在相同数据集上计算得到的。</li>
<li>虽然很难绝对的量化模型的输出，但mAP是一个相对来说很好的度量，许多常用的数据集都是用mAP对比方法。</li>
<li>对于特定类别的AP值可能非常高也可能非常低，这取决于特定数据和类别。所以mAP是一种这种的量。但在分析的时候应该分析一下每一类的AP值，从而知道模型对于那些数据类别表现较好并分析原因。</li>
</ul>
<h3 id="mAP的开源代码"><a href="#mAP的开源代码" class="headerlink" title="mAP的开源代码"></a>mAP的开源代码</h3><ul>
<li><p>计算每多一个detection作为positive下， 对应的pre和rec指标</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">sorted_ind 	= np.argsort(-confidence)  <span class="comment"># 置信度降序排列下的索引</span></span><br><span class="line">BB 		   	= BB[sorted_ind, :]  <span class="comment"># 所有的检测框按照置信度降序排列， 检测框来源于多张图像</span></span><br><span class="line">image_ids 	= [image_ids[x] <span class="keyword">for</span> x <span class="keyword">in</span> sorted_ind] <span class="comment"># 每个检测对应的图像</span></span><br><span class="line">nd 			= len(sorted_ind)   <span class="comment"># 检测结果的个数</span></span><br><span class="line">tp 			= np.zeros(nd)</span><br><span class="line">fp 			= np.zeros(nd)  <span class="comment"># 每个检测的标志位， 1表示是fp， 0表示不是， tp与fp类似</span></span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> range(nd):  <span class="comment"># 遍历每一个检测，判断其是否是positive</span></span><br><span class="line">    R 		= class_recs[image_ids[d]]  <span class="comment"># 对应图像中的标注信息</span></span><br><span class="line">    bb 		= BB[d, :].astype(float)  <span class="comment"># bounding box的4个值</span></span><br><span class="line">    ovmax 	= -np.inf   <span class="comment"># 与ground truth的最大overlap</span></span><br><span class="line">    BBGT 	= R[<span class="string">'bbox'</span>].astype(float)  <span class="comment"># 当前图像对应的所有ground truth boxes</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> BBGT.size &gt; <span class="number">0</span>:  <span class="comment"># 存在gt box， 则计算检测与gt box的iou配对</span></span><br><span class="line">        xmin = np.maximum(BBGT[:, <span class="number">0</span>], bb[<span class="number">0</span>])</span><br><span class="line">        xmax = np.minimum(BBGT[:, <span class="number">2</span>], bb[<span class="number">2</span>])</span><br><span class="line">        ymin = np.maximum(BBGT[:, <span class="number">1</span>], bb[<span class="number">1</span>])</span><br><span class="line">        ymax = np.minimum(BBGT[:, <span class="number">2</span>], bb[<span class="number">2</span>])</span><br><span class="line">        w = np.maximum(xmax - xmin + <span class="number">1</span>, <span class="number">0.</span>)</span><br><span class="line">        h = np.maximum(ymax - ymin + <span class="number">1</span>, <span class="number">0</span>,)</span><br><span class="line">        inters = w * h  	<span class="comment"># intersection</span></span><br><span class="line">        unions = (bb[<span class="number">2</span>] - bb[<span class="number">0</span>] + <span class="number">1.</span>) * (bb[<span class="number">3</span>] - bb[<span class="number">1</span>] + <span class="number">1.</span>) +</span><br><span class="line">        		 (BBGT[:, <span class="number">2</span>] - BBGT[:, <span class="number">0</span>] + <span class="number">1.</span>) *(BBGT[:, <span class="number">3</span>] - BBGT[:, <span class="number">1</span>] + <span class="number">1.</span>) -</span><br><span class="line">            	 inters   <span class="comment"># union</span></span><br><span class="line">                </span><br><span class="line">        ious    = inters / unions</span><br><span class="line">        ovrmax 	= np.max(ious)  <span class="comment"># 与gt boxes存在的最大的iou</span></span><br><span class="line">        jmax 	= np.argmax(ious)  <span class="comment"># 最大iou的gt box的索引</span></span><br><span class="line">    <span class="keyword">if</span> ovmax &gt; ovthresh: 		<span class="comment"># 大于IoU阈值则认为是匹配成功的</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> R[<span class="string">'diffcult'</span>][jmax]:  <span class="comment"># 非diffcult的样本参与评估</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> R[<span class="string">'det'</span>][jmax]:   <span class="comment"># 如果该ground truth没有被分配过检测，则分配</span></span><br><span class="line">                tp[d] = <span class="number">1</span></span><br><span class="line">                R[<span class="string">'det'</span>][jmax] = <span class="number">1</span>  <span class="comment"># 用来保证每个gt只分配最近的检测</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                fp[d] = <span class="number">1</span>   <span class="comment"># 该检测没有分配成功</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        fp[d] = <span class="number">1</span></span><br><span class="line">fp 		= np.cumsum(fp)  <span class="comment"># 累积fp值 fp_a</span></span><br><span class="line">tp 		= np.cumsum(tp)  <span class="comment"># 累积tp值 tp_a</span></span><br><span class="line">rec 	= tp/ float(npos)  <span class="comment"># npos表示所有ground truth的个数</span></span><br><span class="line">pre 	= tp/np.maximum(tp + fp, np.finfo(np.float64).eps)  <span class="comment"># 防止分母为0</span></span><br></pre></td></tr></table></figure>

<p><strong>我认为这部分计算其实是存在问题的</strong></p>
<p>举个例子， 现在有两个gt分别为gt1, gt2, 检测器检测出两个响应d1, d2, 其置信度分别为0.7和0.6，</p>
<p>计算d1, d2与gt1， gt2的iou矩阵如下</p>
<table>
<thead>
<tr>
<th>-</th>
<th>gt1</th>
<th>gt2</th>
</tr>
</thead>
<tbody><tr>
<td>d1</td>
<td>0.8</td>
<td>0.6</td>
</tr>
<tr>
<td>d2</td>
<td>0.7</td>
<td>0.68</td>
</tr>
</tbody></table>
<p>那么按照上面提供的代码计算得到的值<br>$$<br>TP = [1, 0] ;\quad \quad  FP = [0, 1]<br>$$<br>但直观上来看， d2既然不能分配给gt1了，那为什么就不能分配给gt2了呢？而直接就认为d2是false positive了呢？</p>
<p><strong>所以我觉得这部分计算TP， FP的过程还是MOT中的CLEAR指标中方法更加合适，采用贪婪法或者匈牙利算法对检测和gt进行匹配， 匹配之后再进行统计TP和FP。</strong></p>
</li>
<li><p>由pre， rec计算最终的mAP</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">voc_ap</span><span class="params">(rec, pre, use_07_metric=True)</span>:</span></span><br><span class="line">    <span class="string">"""Compute VOC AP given precision and recall. If use_07_metric is true, uses the VOC 07 11-point method (default: False)"""</span></span><br><span class="line">    <span class="keyword">if</span> use_07_metric:  <span class="comment"># 07年方法，即11点插值法</span></span><br><span class="line">        ap = <span class="number">0.</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> np.arange(<span class="number">0.</span>, <span class="number">1.1</span>, <span class="number">0.1</span>):</span><br><span class="line">            <span class="keyword">if</span> np.sum(rec &gt;= t) == <span class="number">0</span>:  <span class="comment"># 这部分主要考虑的是没有任何检测结果产生</span></span><br><span class="line">                p = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                p = np.max(pre[rec &gt;= t])  <span class="comment"># 选择大于该recall值可能取得的最大pre</span></span><br><span class="line">            ap = ap + p // <span class="number">11.</span></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># COCO标准，计算所有点</span></span><br><span class="line">        <span class="comment"># first append sentinel values at the end</span></span><br><span class="line">        mrec 	= np.concatenate([<span class="number">0.</span>], rec, [<span class="number">1.</span>])</span><br><span class="line">        mpre 	= np.concatenate([<span class="number">0.</span>], pre, [<span class="number">1.</span>])</span><br><span class="line">        <span class="comment"># compute the precision, 看上面给的例子，从最右侧开始遍历dets， 逐步找当前最大pre</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(mpre.size <span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>):  <span class="comment"># 降序搜索</span></span><br><span class="line">            mpre[i - <span class="number">1</span>] = np.maximum(mpre[i - <span class="number">1</span>], mpre[i])</span><br><span class="line">        <span class="comment"># 计算每两个recall值之间的区间长度</span></span><br><span class="line">        i = -np.where(mrec[<span class="number">1</span>:] != mrec[:<span class="number">-1</span>])[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># recall的区间长度和对应pre的值构成多条矩形条，求面积和作为AUC的逼近</span></span><br><span class="line">        ap = np.sum(mrec[i+<span class="number">1</span>] - mrec[i]) * mpre[i+<span class="number">1</span>]  <span class="comment"># 从右往左搜，所以应该取mpre[i+1]</span></span><br><span class="line">    <span class="keyword">return</span> ap</span><br></pre></td></tr></table></figure>

<p>上面的代码只考虑了每一类内的AP值，最终的mAP值需要在多个类别的AP中计算均值。</p>
    </div>
  </div>
  
    <div class="copy-right">
      <div class="markdown-body">
        <blockquote>
        
        
          本文作者 : zhouzongwei <br>
        
        原文链接 : <a href>http://yoursite.com/2019/05/28/mAP/</a><br>
        版权声明 : 本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！
        </blockquote>
      </div>
    </div>
  
  
  
    <div class="social-share" style="margin-top: -2rem" data-wechat-qrcode-title="<p>微信扫一扫</p>" data-wechat-qrcode-helper="<p>微信右上角, 扫一扫分享</p>" data-sites="qzone, qq, weibo, wechat, douban, google, facebook, twitter">
  <span style="color: #6b7487; font-size: 1.4rem;">分享到: </span>
</div>
<script src="https://cdn.bootcss.com/social-share.js/1.0.16/js/social-share.min.js" async></script>
  

  
    <div id="reward">
  
    <p id="reward-meta">知识 & 情怀 | 赏或者不赏，我都在这，不声不响</p>
  
  <button id="reward-btn">
    
    <span>打赏</span>
  </button>
  <div id="reward-qrcode">
    
      <div class="reward-qrcode--container">
        <img class="qrcode-img" src="/images/wechatimg.jpg" alt="微信扫一扫, 以资鼓励">
        <p class="qrcode-meta">微信扫一扫, 以资鼓励</p>
      </div>
    
      <div class="reward-qrcode--container">
        <img class="qrcode-img" src="/images/alipayimg.jpg" alt="支付宝扫一扫, 再接再厉">
        <p class="qrcode-meta">支付宝扫一扫, 再接再厉</p>
      </div>
    
  </div>

</div>

<script>
  (() => {
    let button = document.querySelector('#reward-btn'),
      qrcode = document.querySelector('#reward-qrcode'),
      display = false;
    
    button.addEventListener('click', () => {
      qrcode.style.display = display ? 'none' : 'block'
      display = !display
    }, false)
  })()
</script>
  

  <div class="article-footer">
    <div class="article-meta pull-left">
      <span>
        
          <i class="iconfont icon-06tags"></i>标签: 
          
          <span class="span--tag">
            <a href="/tags/deep-learning/">
              #deep-learning
            </a>
          </span>
          
          <span class="span--tag">
            <a href="/tags/object-detection/">
              #object-detection
            </a>
          </span>
          
          <span class="span--tag">
            <a href="/tags/metric/">
              #metric
            </a>
          </span>
          
          <span class="span--tag">
            <a href="/tags/mAP/">
              #mAP
            </a>
          </span>
          
        
      </span>
    </div>
    <div class="article-meta pull-right">
    </div>
  </div>
</div>


  <aside id="sidebar">
    <p id="sidebar-header"></p>
    <ol id="sidebar-toc"></ol>
  </aside>
  <script async>setTimeout(generateToc, 10);</script>


  <nav class="post-navigation">
    
      <div class="nav-pre">
        <i class="iconfont icon-prev"></i>
        上一篇:
        <a href="/2019/05/28/normalization-layers/" target="_self">深度学习-Normalization layers</a>
      </div>
    
    
      <div class="nav-next">
        下一篇:
        <a href="/2019/05/29/nms-and-softnms/" target="_self">深度学习-nms 和 softnms [代码]</a>
        <i class="iconfont icon-next"></i>
      </div>
    
  </nav>

  
    <a href="#comment" class="comment-anchor"></a>
<div class="comment-title"><i class="iconfont icon-footprint"></i> 留下足迹 <i class="iconfont icon-footprint"></i></div>
<div id="vcomments"></div>

<script defer>
  if( true ) {
    let path = getRealPath()
    new Valine({
      el: "#vcomments",
      appId: "oGELcUvlMiFClUUpxn7V3qUo-gzGzoHsz",
      appKey: "fWABYGLTAoV1LT4LYzh1PNmQ",
      notify: false,
      verify: false,
      avatar: "robohash",
      placeholder: "正确填写邮箱, 才能及时收到回复哦♪(^∇^*)",
      path
    });
  }
</script>
   

  
    <script defer>
const valineAPI = (() => {
  try {
    AV.init("oGELcUvlMiFClUUpxn7V3qUo-gzGzoHsz", "fWABYGLTAoV1LT4LYzh1PNmQ");
  } catch(error) {}
  const isExist = (identity) => {
    identity = identity || getRealPath();
    let query = new AV.Query('Timer');
    return new Promise((resolve, reject) => {
      query.equalTo("identity", identity);
      query.find().then(results => {
        resolve(results.length > 0);
      }, error => reject(error));
    })
  }

  const _get = (identity) => {
    let query = null;
    if(identity && identity instanceof Array){
      let querys = [];
      for(let i = 0; i < identity.length; ++i) {
        querys[i] = new AV.Query('Timer');
        querys[i].equalTo('identity', identity[i]);
      }
      query = AV.Query.or.apply(null ,querys);
    } else {
      identity = identity || getRealPath();
      query = new AV.Query("Timer");
      query.equalTo("identity", identity);
    }

    return new Promise((resolve, reject) => {
      query.find()
      .then(results => resolve(results))
      .catch(error => reject(error))
    })
  }

  const create = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
      let Todo = AV.Object.extend('Timer');
      let todo = new Todo();
      todo.set("times", 1);
      todo.set("identity", identity);
      todo.save().then(res => resolve(true), error => reject(error));
    })
  }

  const update = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
      let query = new AV.Query('Timer');
      query.equalTo("identity", identity);
      query.find().then(todos => {
        todos.forEach(todo => {
          todo.set("times", todo.attributes.times + 1);
        });
        return AV.Object.saveAll(todos);
      }).then(todos => resolve(true), error => reject(error));
    })
  }

  return {
    isExist,
    _get,
    update,
    create
  }
})()

const calcAndWriteTimes = () => {
  let isPost = true;

  let timerAllDOM = document.querySelectorAll(".article-timer");

  if(isPost) {
    let identity = timerAllDOM[0].getAttribute("data-identity");
    valineAPI.isExist(identity)
    .then(exist => {
      if(exist) {
        return valineAPI.update(identity);
      }
      return new Promise(resolve => resolve(true));
    })
    .then( succuess => valineAPI._get(identity))
    .then( result => timerAllDOM[0].innerText = result[0].attributes.times)
    .catch(error => console.log(error.message))
    return ;
  }

  let timerDOMCache = {};

  for(let timerDOM of timerAllDOM) {
    let identity = timerDOM.getAttribute("data-identity");
    if(timerDOMCache.hasOwnProperty(identity)){
      timerDOMCache[identity].dom.push(timerDOM);
    }else{
      timerDOMCache[identity] = {
        dom: [timerDOM],
        times: undefined
      };
    }
  }

  let identities = Object.keys(timerDOMCache);
  valineAPI._get(identities).then(results => {
    for(let result of results) {
      let {identity, times} = result.attributes;
      timerDOMCache[identity].times = times;
      timerDOMCache[identity].dom.map(item => item.innerText = times);
    }
    for(let identity of identities) {
      if(timerDOMCache[identity].times){
        continue;
      }
      timerDOMCache[identity].dom.map(item => item.innerText = 1);
      valineAPI.create(identity);
    }
  }).catch(error => console.log(error.message))
}

if(true){
  calcAndWriteTimes();
}
</script>
   

</div>


      <footer>
  <p class="site-info">
    博客已萌萌哒运行<span id="time-to-now"></span><span class="my-face">(●'◡'●)ﾉ♥</span>
    <br>
    Theme - <a href="https://github.com/dongyuanxin/theme-bmw">BMW</a> | Made With 💗 | Powered by <a href="https://godbmw.com/">GodBMW</a>
    <br>
    
  </p>
</footer>



<script>
const timeToNowDOM = document.querySelector("#time-to-now");
const startTimestamp = new Date(2018, 1, 10).getTime();

const updateTimeStr = () => {
  let offset = parseInt(
      (new Date().getTime() - startTimestamp) / 1000,
      10
    ),
    day = Math.floor(offset / 86400),
    hour = Math.floor((offset % 86400) / 3600),
    minute = Math.floor(((offset % 86400) % 3600) / 60),
    second = Math.floor(((offset % 86400) % 3600) % 60);
  timeToNowDOM.innerHTML =
    day + "天" + hour + "小时" + minute + "分钟" + second + "秒";
  setTimeout(updateTimeStr, 500);
}

setTimeout(updateTimeStr, 500);
</script>


      <div class="back-to-top hidden">
  <span>
    <i class="iconfont icon-60"></i><span></span>%
  </span>
</div>

<script>
const updateIconToTop = percent => {
  let dom = document.querySelector(".back-to-top span span");
  dom.innerText = percent;
  if(percent < 1) {
    document.querySelector(".back-to-top").className = "back-to-top hidden";
  } else {
    document.querySelector(".back-to-top").className = "back-to-top";
  }
}

const handleScoll = () => {
  let isRunning = false;
  return () => {
    if (isRunning) return;
    isRunning = true;
    window.requestAnimationFrame(timestamp => {
      let scrollTop =
          document.documentElement.scrollTop || document.body.scrollTop,
        scrollHeight =
          document.documentElement.scrollHeight ||
          document.body.scrollHeight,
        clientHeight =
          document.documentElement.clientHeight ||
          document.body.clientHeight;
      isRunning = false;
      if (scrollTop <= 1) {
        updateIconToTop(0);
        return;
      }
      if (scrollTop + clientHeight >= scrollHeight) {
        updateIconToTop(100);
      } else {
        updateIconToTop(parseInt(
          100 * scrollTop / (scrollHeight - clientHeight),
          10
        ));
      }
    });
  };
}

const backToTop = () => {
  let scrollTop =
      document.documentElement.scrollTop || document.body.scrollTop,
    delay = 10,
    time = 200;
  if (scrollTop <= 20) {
    document.documentElement.scrollTop = 0;
    document.body.scrollTop = 0;
    return;
  }
  let step = Math.ceil(scrollTop * delay / time);
  let timer = setInterval(() => {
    scrollTop =
      document.documentElement.scrollTop || document.body.scrollTop;
    if (scrollTop - step <= 0) {
      document.documentElement.scrollTop = 0;
      document.body.scrollTop = 0;
      clearInterval(timer);
    } else {
      document.documentElement.scrollTop = scrollTop - step;
      document.body.scrollTop = scrollTop - step;
    }
  }, delay);
}

document.addEventListener("scroll", handleScoll(), false);

document.querySelector(".back-to-top").addEventListener("click", backToTop, false);

</script>

    </div>

    
      <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
<script>
  (() => {
    const mathjaxConfig = {
      showProcessingMessages: false, //关闭js加载过程信息
      messageStyle: "none", //不显示信息
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
        displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
        skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
      },
      "HTML-CSS": {
        availableFonts: ["STIX", "TeX"], //可选字体
        showMathMenu: false //关闭右击菜单显示
      }
    }

    let mathjaxInterval = setInterval(() => {
      if(!window.MathJax){
        return;
      }
      window.MathJax.Hub.Config(mathjaxConfig)
      window.MathJax.Hub.Queue(["Typeset", MathJax.Hub, document.getElementById('app')])

      clearInterval(mathjaxInterval)
    }, 10)    
  })()
</script>
    

    <script src="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script>
<script async>
  let fancyTimer = setInterval(function(){
    if(!window.$){
      return;
    }
    $(document).ready(function() {
      $(".post img").each(function () {
        if($(this).parent().get(0).tagName.toLowerCase() === "a") {
          return;
        }
        // $(this).attr("data-fancybox", "gallery"); // if you add 'data-fancybox', img will display after showed
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "gallery");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      });
      
      clearInterval(fancyTimer);
    });
  }, 10);
</script>

    
  </body>

</html>
